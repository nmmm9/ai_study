# 3주차: Embedding & Vector DB - juwon

## 기술 스택

| 항목           | 선택                                                            | 대안                         | 선택 이유                                     |
| ------------ | ------------------------------------------------------------- | -------------------------- | ----------------------------------------- |
| Embedding 모델 | sentence-transformers (paraphrase-multilingual-MiniLM-L12-v2) | OpenAI embedding API       | 한국어 포함 다국어 지원이 가능하고, 로컬에서 무료로 실습할 수 있기 때문 |
| Vector DB    | FAISS                                                         | Pinecone, Milvus, Weaviate | 별도 서버 구축 없이 로컬에서 빠르게 실험 가능하며, 소규모 데이터에 적합 |
| 유사도 방식       | Cosine Similarity (Inner Product + 정규화)                       | L2 Distance                | 문장 의미 유사도 측정에 코사인 유사도가 일반적으로 많이 사용됨       |

---

## 핵심 구현

* 주요 로직 설명:

1. 문서를 청킹한 후 각 청크를 sentence-transformers 모델을 사용해 벡터로 변환하였다.
2. `normalize_embeddings=True` 옵션을 통해 L2 정규화를 수행하여, 내적(Inner Product)이 코사인 유사도와 동일하게 동작하도록 설정하였다.
3. FAISS의 `IndexFlatIP`를 사용하여 벡터 인덱스를 생성하였다.
4. 모든 청크 임베딩을 인덱스에 추가한 뒤, 사용자의 질문을 동일한 방식으로 임베딩하였다.
5. `index.search()`를 통해 상위 k개의 유사 벡터를 검색하고, 해당 청크를 반환하도록 구현하였다.

기존 2주차의 단순 키워드 매칭 방식과 비교했을 때, 조사나 어미 차이로 인해 검색되지 않던 문장들도 의미 기반으로 유사하게 매칭되는 것을 확인할 수 있었다.

* 코드 실행 방법:

1. 필요한 라이브러리 설치

   ```
   pip install sentence-transformers faiss-cpu
   ```
2. 문서를 청킹한 뒤 `EmbeddingStore.build(chunks)` 실행
3. 질문 입력 시 `search(query, top_k)` 호출

---

## WHY (의사결정 기록)

1. **Q**: 왜 이 방식을 선택했는가?
   **A**:
   2주차에서 구현한 키워드 기반 검색은 단어가 정확히 일치하지 않으면 검색되지 않는 한계가 있었다. 이를 개선하기 위해 의미 기반 검색이 필요하다고 판단하였다.
   FAISS는 별도의 서버 없이도 벡터 인덱싱과 검색이 가능하고, 구조가 단순하여 벡터 검색 원리를 이해하는 데 적합하다고 생각하여 선택하였다.

2. **Q**: 다르게 구현한다면 어떻게 했을까?
   **A**:
   대규모 문서를 다루는 상황이라면 `IndexFlatIP` 대신 IVF나 HNSW 기반 인덱스를 사용해 검색 속도를 개선할 수 있을 것이다.
   또한 클라우드 환경에서 운영한다면 Pinecone과 같은 서버형 Vector DB를 사용해 확장성과 관리 편의성을 확보하는 방법도 고려할 수 있다.

---

## 트러블슈팅 로그

| # | 문제 상황                   | 에러 메시지                                       | 원인 (Root Cause)                     | 해결 방법                             |
| - | ----------------------- | -------------------------------------------- | ----------------------------------- | --------------------------------- |
| 1 | FAISS 설치 후 import 오류 발생 | ModuleNotFoundError: No module named 'faiss' | 환경에 맞는 패키지가 설치되지 않음                 | Windows 환경에서 `faiss-cpu`로 재설치     |
| 2 | 검색 결과 점수가 이상하게 낮게 출력됨   | 별도 에러 없음                                     | 임베딩 정규화를 하지 않아 코사인 유사도가 제대로 계산되지 않음 | `normalize_embeddings=True` 옵션 추가 |

---

## 회고

* 이번 주 배운 점:
  단순 키워드 매칭과 의미 기반 검색의 차이를 직접 비교해 보면서 벡터 임베딩의 필요성을 체감할 수 있었다.
  특히, 임베딩 정규화와 유사도 계산 방식에 따라 검색 결과가 달라진다는 점이 인상적이었다.
  또한 Vector DB는 반드시 Oracle 같은 전통적인 데이터베이스가 아니라, 벡터 검색에 특화된 인덱스 구조라는 점을 이해하게 되었다.

* 다음 주 준비할 것:
