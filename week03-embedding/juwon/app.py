"""
3ì£¼ì°¨: Embedding & Vector DB - Streamlit ì›¹ ì•±
sentence-transformers + FAISS ê¸°ë°˜ ì˜ë¯¸ ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ
2ì£¼ì°¨ í‚¤ì›Œë“œ ë§¤ì¹­ â†’ 3ì£¼ì°¨ ì„ë² ë”© ê²€ìƒ‰
"""

import sys
import tempfile
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

# chunking_chat.pyì—ì„œ DocumentLoader, TextChunker ì¬ì‚¬ìš© (2ì£¼ì°¨ ì½”ë“œ ê·¸ëŒ€ë¡œ)
sys.path.insert(0, str(Path(__file__).parent))
from chunking_chat import DocumentLoader, TextChunker
from embedding_search import EmbeddingStore

load_dotenv(Path(__file__).parent / ".env")

# â”€â”€ ìƒìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MODEL = "gpt-4o-mini"
SYSTEM_PROMPT = (
    "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì·¨ì—… ìƒë‹´ AIì…ë‹ˆë‹¤. "
    "ì œê³µëœ ì·¨ì—…ê³µê³  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤. "
    "ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì—†ë‹¤ê³  ì†”ì§í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”."
)
CHUNK_SIZE = 500
OVERLAP = 50
TOP_K = 5

STRATEGY_LABELS = {
    "fixed":     "Fixed â€” ê³ ì • í¬ê¸° ë¶„í• ",
    "separator": "Separator â€” êµ¬ë¶„ì ì¬ê·€ ë¶„í• ",
    "paragraph": "Paragraph â€” ë‹¨ë½ ë‹¨ìœ„ ë¶„í• ",
}

# â”€â”€ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def init_session():
    defaults = {
        "messages":    [],
        "chunks":      [],
        "chunker":     None,
        "raw_text":    "",
        "client":      OpenAI(),
        "token_total": 0,
        "embed_store": None,  # EmbeddingStore, ë¬¸ì„œ ë¡œë“œ ì‹œ ì´ˆê¸°í™”
    }
    for key, val in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = val


# â”€â”€ ì²­í¬ ê²€ìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def find_relevant_chunks(query: str) -> list[str]:
    """ì„ë² ë”© ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì²­í¬ ìƒìœ„ TOP_Kê°œ ë°˜í™˜"""
    store = st.session_state.embed_store
    if store is None or not store.is_built:
        return []
    results = store.search(query, top_k=TOP_K)
    return [chunk for _score, chunk in results]


# â”€â”€ OpenAI ìŠ¤íŠ¸ë¦¬ë° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def stream_chat(messages: list[dict]):
    """st.write_streamì— ë„˜ê¸¸ ì œë„ˆë ˆì´í„°"""
    stream = st.session_state.client.chat.completions.create(
        model=MODEL,
        messages=messages,
        stream=True,
        stream_options={"include_usage": True},
    )
    for chunk in stream:
        if chunk.choices and chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content
        if chunk.usage:
            st.session_state.token_total += chunk.usage.total_tokens


def build_messages(context: str = "") -> list[dict]:
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    if context:
        messages.append({"role": "system", "content": context})
    messages.extend(st.session_state.messages)
    return messages


# â”€â”€ ë¬¸ì„œ ë¡œë“œ + ì²­í‚¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_and_chunk(text: str, strategy: str):
    st.session_state.raw_text = text
    st.session_state.chunker = TextChunker(
        strategy=strategy, chunk_size=CHUNK_SIZE, overlap=OVERLAP
    )
    st.session_state.chunks = st.session_state.chunker.chunk(text)

    # ì²­í¬ê°€ ë°”ë€” ë•Œë§ˆë‹¤ ì„ë² ë”© ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
    with st.spinner("ì„ë² ë”© ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘... (ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œê°€ ìˆì„ ìˆ˜ ìˆì–´ìš”)"):
        if st.session_state.embed_store is None:
            st.session_state.embed_store = EmbeddingStore()
        st.session_state.embed_store.build(st.session_state.chunks)


# â”€â”€ ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    st.set_page_config(
        page_title="ì·¨ì—…ê³µê³  ì±—ë´‡",
        page_icon="ğŸ’¼",
        layout="wide",
    )
    init_session()

    # â”€â”€ ì‚¬ì´ë“œë°” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    with st.sidebar:
        st.title("âš™ï¸ ì„¤ì •")

        # 1. ì²­í‚¹ ì „ëµ ì„ íƒ
        st.subheader("1. ì²­í‚¹ ì „ëµ")
        strategy = st.radio(
            label="ì „ëµ",
            options=list(STRATEGY_LABELS.keys()),
            index=2,  # paragraph ê¸°ë³¸ê°’
            format_func=lambda x: STRATEGY_LABELS[x],
            label_visibility="collapsed",
        )

        # ì „ëµì´ ë°”ë€Œë©´ ê¸°ì¡´ ë¬¸ì„œ ì¬ì²­í‚¹
        if st.session_state.raw_text:
            if (st.session_state.chunker is None
                    or st.session_state.chunker.strategy != strategy):
                load_and_chunk(st.session_state.raw_text, strategy)

        st.divider()

        # 2. ë¬¸ì„œ ë¡œë“œ
        st.subheader("2. ë¬¸ì„œ ë¡œë“œ")

        # ìƒ˜í”Œ íŒŒì¼ ë²„íŠ¼
        default_path = Path(__file__).parent / "job_postings.md"
        if st.button("ğŸ“„ ìƒ˜í”Œ íŒŒì¼ ì‚¬ìš©", use_container_width=True):
            load_and_chunk(DocumentLoader.load(str(default_path)), strategy)
            st.success(f"ë¡œë“œ ì™„ë£Œ â€” {len(st.session_state.chunks)}ê°œ ì²­í¬")

        # ì§ì ‘ ì—…ë¡œë“œ
        uploaded = st.file_uploader("ë˜ëŠ” ì§ì ‘ ì—…ë¡œë“œ", type=["md", "pdf"])
        if uploaded:
            if uploaded.name.endswith(".pdf"):
                with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as tmp:
                    tmp.write(uploaded.read())
                    raw = DocumentLoader.load(tmp.name)
            else:
                raw = uploaded.read().decode("utf-8")
            load_and_chunk(raw, strategy)
            st.success(f"ë¡œë“œ ì™„ë£Œ â€” {len(st.session_state.chunks)}ê°œ ì²­í¬")

        st.divider()

        # 3. ì²­í¬ ëª©ë¡
        if st.session_state.chunks:
            st.subheader(f"3. ì²­í¬ ëª©ë¡ ({len(st.session_state.chunks)}ê°œ)")
            for i, chunk in enumerate(st.session_state.chunks, 1):
                preview = chunk[:45].replace("\n", " ")
                with st.expander(f"[{i:02d}] {len(chunk)}ì  {preview}â€¦"):
                    st.text(chunk)

        st.divider()

        # ì´ˆê¸°í™” + í† í°
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
                st.session_state.messages = []
                st.rerun()
        with col2:
            st.metric("ëˆ„ì  í† í°", f"{st.session_state.token_total:,}")

    # â”€â”€ ë©”ì¸ ì±„íŒ… ì˜ì—­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    st.title("ğŸ’¼ ì·¨ì—…ê³µê³  ì±—ë´‡")
    st.caption("3ì£¼ì°¨ â€” ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰ + GPT ì§ˆì˜ì‘ë‹µ")

    if not st.session_state.chunks:
        st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë¬¸ì„œë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return

    # ì´ì „ ëŒ€í™” í‘œì‹œ
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if msg["role"] == "assistant" and "strategy" in msg:
                label = STRATEGY_LABELS[msg["strategy"]]
                chunks_used = msg["chunks_used"]
                if chunks_used > 0:
                    st.caption(f"ğŸ“ ì°¸ì¡° ì²­í¬ {chunks_used}ê°œ / ì „ëµ: {label}")
                else:
                    st.caption(f"âš ï¸ ê´€ë ¨ ì²­í¬ ì—†ìŒ / ì „ëµ: {label}")

    # ì…ë ¥ì°½
    if prompt := st.chat_input("ì·¨ì—…ê³µê³ ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”"):
        # ì‚¬ìš©ì ë©”ì‹œì§€
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # ê´€ë ¨ ì²­í¬ ê²€ìƒ‰
        relevant = find_relevant_chunks(prompt)
        context = ""
        if relevant:
            context = "ì•„ë˜ëŠ” ê´€ë ¨ ì·¨ì—…ê³µê³  ë‚´ìš©ì…ë‹ˆë‹¤:\n\n" + "\n\n---\n\n".join(relevant)

        # AI ì‘ë‹µ
        with st.chat_message("assistant"):
            if relevant:
                st.caption(f"ğŸ“ ì°¸ì¡° ì²­í¬ {len(relevant)}ê°œ / ì „ëµ: {strategy}")
            else:
                st.caption("âš ï¸ ê´€ë ¨ ì²­í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ì„ë² ë”© ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)")
            response = st.write_stream(stream_chat(build_messages(context)))

        st.session_state.messages.append({
            "role": "assistant",
            "content": response,
            "strategy": strategy,
            "chunks_used": len(relevant),
        })


if __name__ == "__main__":
    main()
