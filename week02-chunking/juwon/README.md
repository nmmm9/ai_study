# 2주차: Chunking - juwon

---

## 기술 스택

| 항목    | 선택                            | 대안     | 선택 이유                  |
| ----- | ----------------------------- | ------ | ---------------------- |
| 언어    | Python                        | -      | 수업 및 실습 환경에 맞춤         |
| 문서 형식 | Markdown (.md)                | PDF    | 텍스트 구조 확인과 분할 실험이 쉬움   |
| 청킹 전략 | fixed / separator / paragraph | hybrid | 전략별 차이 비교를 위해 여러 방식 구현 |
| 실행 방식 | CLI 기반                        | 웹 UI   | 빠르게 실험하고 로그 확인하기 위함    |
| 검색 방식 | Top-K 기반 유사도 검색               | -      | 기본적인 RAG 구조 이해 목적      |

---

## 핵심 구현

### 주요 로직 설명:

* Markdown 파일을 로드
* 선택한 전략에 따라 텍스트를 분할

  * fixed: 일정 길이 기준으로 나눔
  * separator: 특정 구분자 기준 분할
  * paragraph: 문단 단위로 분할
* 사용자 질문 입력
* 분할된 청크 중에서 유사한 청크 Top-K개 선택
* 선택된 청크를 기반으로 답변 생성
* 참조 청크 수와 토큰 수 출력

전략을 실행 중에 바꿀 수 있도록 구성해서 같은 질문을 여러 방식으로 비교할 수 있게 만들었다.

---

### 코드 실행 방법

```bash
cd week02-chunking/juwon
python chunking_chat.py
```

사용 예시:

```
load job_postings.md paragraph
카카오 전형절차랑 네이버 자격요건 동시에 알려줘
```

---

## WHY (의사결정 기록)

### 1. Q: 왜 이 방식을 선택했는가?

A:

청킹 전략에 따라 검색 결과가 어떻게 달라지는지 직접 비교해보고 싶었다.
특히 채용공고 문서는 회사별로 문단이 나뉘어 있어서 paragraph 방식이 더 적합할 것 같다고 생각했다.

또한 fixed 방식은 단순하지만 문장이 중간에 잘릴 수 있어서 실제 검색 품질에 어떤 영향을 주는지 확인하고 싶었다.

전략을 실시간으로 바꿀 수 있도록 만든 이유는 같은 질문을 반복해서 테스트하기 위해서였다.

---

### 2. Q: 다르게 구현한다면 어떻게 했을까?

A:

* 문단 기준으로 자른 뒤, 너무 긴 문단은 다시 분할하는 hybrid 방식으로 구현해볼 수 있을 것 같다.
* 청크 간 일부 내용을 겹치게(overlap) 해서 문맥 손실을 줄이는 방법도 적용해보고 싶다.
* 복합 질문(예: 두 회사 정보를 동시에 묻는 질문)의 경우 질문을 나눠서 검색하는 방식도 시도해볼 수 있을 것 같다.

---

## 트러블슈팅 로그

| # | 문제 상황                     | 에러 메시지           | 원인 (Root Cause)               | 해결 방법           |
| - | ------------------------- | ---------------- | ----------------------------- | --------------- |
| 1 | 복합 질문에서 한 회사 정보가 누락됨      | "문서에 포함되어 있지 않음" | Top-K 결과 안에 해당 회사 청크가 포함되지 않음 | 검색 개수(K) 증가     |
| 2 | fixed 전략에서 문장이 잘려 의미가 어색함 | 없음               | 고정 길이 분할의 한계                  | paragraph 전략 추가 |
| 3 | 전략에 따라 답변 내용이 달라짐         | 없음               | 청크 단위 차이로 검색 결과가 달라짐          | 전략별 비교 실험 진행    |

---

## 회고

### 이번 주 배운 점:

* 청킹 방식에 따라 검색 결과가 크게 달라질 수 있다는 점을 직접 확인했다.
* LLM이 잘못 답하는 경우도 실제로는 검색 단계에서 필요한 정보가 전달되지 않았기 때문이라는 것을 알게 되었다.
* Top-K 값이 작으면 복합 질문에서 일부 정보가 빠질 수 있다는 점을 경험했다.
* paragraph 방식이 구조적인 문서에는 비교적 안정적인 결과를 보여줬다.

---

### 다음 주 준비할 것:

* 임베딩 모델 개념 정리
* 어떤 임베딩 모델을 사용할지 비교
* 벡터 DB 개념 이해
* 간단한 벡터 DB 구축 및 검색 실습
* 청킹 + 임베딩 + 검색을 하나의 흐름으로 연결해보기


원하면
조금 더 “개발 일지 느낌”으로 바꿔줄까? 아니면 지금 톤이 제일 괜찮아 보여?
