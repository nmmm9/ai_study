# 2주차: *Chunking - minseon

## 기술 스택
| 항목 | 선택 | 대안 | 선택 이유 |
|------|------|------|----------|
|Chunking 방식|Recursive Character Splitting(재귀적 청킹)|Fixed Size, Sentence Splitter |구분자 우선순위(문단→줄바꿈→문장→단어)로 의미 단위를 최대한 보존하면서 size 제한도 준수함 |
|PDF 로더|pymupdf (fitz)|PyPDFLoader, pdfplumber| 한국어 폰트 인코딩을 직접 처리해 글자 깨짐 현상 최소화. 실제 어떤 한글 글자(유니코드)와 연결되어 있는지 PDF 내부의 숨겨진 매핑 테이블(Encoding/CMap)을 샅샅이 뒤져서 직접 해독(Decoding)해서 글자 깨짐 적음|
|Markdown 분할|MarkdownHeaderTextSplitter|일반 텍스트 분할| 문서의 제목 구조(#, ##, ### 등)를 기준으로 텍스트를 나누고 이 계층 정보를 메타데이터로 보존함. 그래서 RAG 검색했을때 AI가 텍스트의 전체 문맥과 출처 위치를 정확히 파악할 수 있어서 엉뚱한 맥락에서 오답을 낼 확률을 크게 줄여줌.|
|chunk_size|900자|500자, 1000자|500자로 자르면 너무 짧아서 문맥이 끊겨 AI가 전체 내용을 이해하기 부족할거같고 1000자 이상으로 길게 자르면 쓸데없는 정보까지 포함되어 검색의 정확도가 떨어질 위험이 있을수도있기때문이다.|
|chunk_overlap|90자 (chunk_size의 10%)|0자, 200자|청크가 나뉘는 경계선에서 중요한 문장이나 단어가 반으로 잘려 검색에서 누락되는 것을 막기위해 앞 청크의 끝부분을 다음 청크의 시작부분에 살짝 겹쳐서 이어줄거임.|
|라이브러리|LangChain text splitters|llama-index, 직접 구현|통합의 편리함과 뛰어난 호환성: 문서 로더와 텍스트 분할기가 이미 잘 통합되어 있어 복잡한 코드를 간단하게 줄여주고 잘라낸 데이터를 저장하는 다양한 벡터 DB(Chroma, Pinecone 등)와의 연동 파이프라인까지 내장되어 있어 추후 시스템을 확장하거나 DB를 변경할 때도 호환성 걱정 없이 유연하게 대처할 수 있음.|

## 핵심 구현
- 주요 로직 설명:
  1. 문서 로딩 : 파일 확장자(.pdf / .md / .txt)를 자동 감지해 적절한 로더로 텍스트 추출
     - PDF ->  fitz.open() (pymupdf): 페이지별 get_text()로 한국어 인코딩 안전하게 추출
     - Markdown -> open() + MarkdownHeaderTextSplitter: 헤더 구조를 메타데이터로 보존
  2. 텍스트 분할 :`RecursiveCharacterTextSplitter로 구분자 우선순위에 따라 재귀 분할
     - 우선순위: `\n\n` , `\n` , `. ` , `? ` , `! ` , ` ` , `""`
     - chunk_size=900, chunk_overlap=90 (한국어 문맥 보존 최적화)
  3. 결과 출력 : 총 청크 수 / 평균 최소 최대 길이 통계 + 각 청크 미리보기 80자 출력

- 코드 실행 방법:
  ```bash
  # 패키지 설치
  pip install -r requirements.txt

  # Markdown 파일 분할 (기본값: chunk_size=900, overlap=90)
  python chunker.py sample.md

  # PDF 파일 분할
  python chunker.py 파일명.pdf

  # 옵션 직접 지정
  python chunker.py sample.md --chunk-size 600 --chunk-overlap 60

  # Markdown 헤더 기반 분할도 함께 출력
  python chunker.py sample.md --md-headers
  ```

## WHY (의사결정 기록)
1. **Q**: 왜 이 방식을 선택했는가?
   **A**: 청킹방식으로 재귀적 분할을 선택했다 왜냐하면 글자 수만 맞추는 고정 크기(Fixed Size)분할은 문장이 중간에 뚝 끊겨 의미가 훼손될 위험이 크고 AI 모델로 의미를 파악해 자르는 의미 기반(Semantic)분할은 품질은 좋지만 속도가 느리고 비용이 많이 들기 때문에 가장 적절한게 문단 -> 문장 -> 단어 순으로 유연하게 잘라 문맥 보존과 크기 제한의 균형을 가장 잘 맞출 수 있는 재귀적 분할이라고 생각해서ㅓ 선택했다. 
한국어 PDF 문서를 다룰 때 가장 흔하게 겪는 폰트 인코딩(글자 깨짐) 문제를 방지하고 텍스트를 안정적으로 추출하기 위해 한국어 처리 성능이 뛰어난 PyMuPDF를 선택했다.

2. **Q**: 다르게 구현한다면 어떻게 했을까?
   **A**: 임베딩 모델을 활용해 텍스트의 실제 의미와 주제가 바뀌는 지점을 스스로 찾아내어 분할하는 의미 기반 청킹(Semantic Chunking)으로 구현했을거같다.
   

## 트러블슈팅 로그
| # | 문제 상황 | 에러 메시지 | 원인 (Root Cause) | 해결 방법 |
|---|----------|-----------|-------------------|----------|
| 1 | | | | |

## 회고
- 이번 주 배운 점: RAG 파이프라인의 전체 답변 품질을 좌우하는 문서 로딩과 청킹(Chunking)에 대해서 알게 되었다. LLM의 입력 제한 한계를 극복하기 위해 문서를 쪼개는 과정에서 문맥 보존과 비용 효율의 균형을 맞춘재귀적분할 방식이 가장 실용적인 선택인걸 알게되었다. pymupdf처럼 한국어 인코딩에 안정적인 로더를 사용하=해야한다는 것도 알게 되었다.
- 다음 주 준비할 것: 임베딩 벡터, 벡터 DB 알아오기 (깃허브에 익숙해지기)































*Chunking : 긴 텍스트를 작은 조각(chunk)으로 나누는 작업
왜 필요함 ? LLM(언어 모델)은 한 번에 처리할 수 있는 텍스트 길이(Context Window)가 제한되어있음. 그래서 의미 있는 단위로 잘라서 관리하기 
1. 컨텍스트 윈도우 제한 : LLM에 한번에 넣을 수있는 토큰수가 제한 되어있음
2. 검색 정확도 : 문서 전체보다 관련 부분만 검색해야 정확한 답변 
3. 비용절감 : 필요한 chunk만 전달하면 토큰 사용량 감소
4. **임베딩 품질 : 짧고 의미있는 텍스트일수록 벡터임베딩 품질 좋음 

**사람의 언어를 AI가 이해할 수 있는 숫자(좌표)로 바꾸는 작업 의미가 비슷한 단어나 문장은 AI의 머릿속에서 서로 가까운 위치에 놓임 

작동순서 
원본문서(PDF) ----chunking----> [chunk 1] [chunk 2] [chunk 3] ----embedding(-> veter DB -> 검색 -> LLM 답변)----> RAG 파이프라인에 활용 

오버랩 (Overlap) : 청킹을 할 때 조각과 조각 사이의 문맥이 뚝 끊기는 것을 막기 위해 오버랩(겹침) 기법 사용. 

원리: 1번 조각의 끝부분 일부를 2번 조각의 시작부분에 중복해서 포함시킴

효과: 앞뒤 조각이 연결고리를 가지게 되어 검색할 때 중요한 정보가 조각 사이에 걸쳐 있어서 누락되는 문제를 막아줌

청킹종류 
- 고정 크기 청킹 (Fixed-size Chunking) : 글자 수나 토큰 수를 정해두고 기계적으로 자르는 방식. (예: 무조건 500자마다 자르기)
장점: 구현이 가장 쉽고 처리 속도가 빠름
단점: 문장이나 단어 중간이 잘릴 수 있어서 문맥(의미)이 끊어질 위험이 큼

-  문법/구조 기반 청킹 (Structural/Syntax Chunking) : 문장 기호(마침표, 쉼표)나 줄바꿈, 문단 단위 등 글의 구조를 기준으로 자르는 방식. 
장점: 고정 크기 방식보다 문맥이 훨씬 자연스러움
단점: 어떤 문단은 너무 길고 어떤 문단은 너무 짧아질 수 있어 크기가 들쭉날쭉임

- 재귀적 청킹 (Recursive Chunking) : 큰 단위(문단)부터 먼저 자르려고 시도. 크기가 너무 크면 점점 작은 단위(문장 -> 단어)로 재귀적으로 쪼개는 방식. 
장점: 크기 제한을 맞추면서도 의미가 깨지는 것을 최대한 방지할 수 있음 

- 의미 기반 청킹 (Semantic Chunking) : AI(임베딩 모델)를 활용해 텍스트의 의미를 분석하고 내용의 주제가 바뀌는 부분을 찾아서 그 경계에서 자르는 방식. 
장점: 정보의 흐름과 문맥을 가장 완벽하게 보존함
단점: 계산이 복잡하고 처리 비용이 많이 든다


PDF 로더 : AI(LLM)나 RAG 시스템이 PDF 문서를 읽고 이해할 수 있도록 PDF 파일 안에 있는 글자, 표, 그림 등을 순수한 텍스트(Text) 데이터로 뽑아내 주는 도구(라이브러리).

1. PyPDFLoader (pypdf)
LangChain 등에서 가장 기본적으로 제공되는 표준 로더
장점: 설치가 쉽고 가볍고 코드가 단순
단점: 한국어 처리 능력이 가장 떨어짐. 영문 위주로 설계되어 있어서 조금만 복잡한 폰트나 레이아웃이 있는 한글 PDF를 만나면 글자 깨뜨림
2. PyMuPDF (fitz)
PDF의 시각적 렌더링 엔진을 기반으로 작동하는 아주 강력한 도구(파이썬 코드에서 import fitz로 사용)
장점: 압도적인 속도: 다른 로더들보다 텍스트를 뽑아내는 속도가 엄청 빠름. 한글 텍스트 추출이 상당히 안정적. 텍스트뿐만 아니라 이미지나 다른 정보도 잘가져옴. 
단점: 라이선스(AGPL) 제한있음 (상용 서비스 개발 시 주의) 
3. pdfplumber
문서의 구조를 시각적으로 분석하여 글자, 선, 사각형 단위로 정밀하게 뜯어보는 로더
장점: PDF 내부의 문자 매핑 정보(CMap)를 직접 꼼꼼하게 추적하고 해석. PDF 내의 표(Table)를 추출할 때도 레이아웃이 안 망가지게 잘 가져옴
단점: 한 글자 한 글자 정밀하게 분석하느라 처리 속도가 좀 느림
