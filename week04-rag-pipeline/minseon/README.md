# 4주차: RAG 파이프라인 - minseon

*RAG란? Retrieval-Augmented Generation — LLM이 모르는 지식을 "검색해서 주입"하는 기법

RAG 파이프라인	: LLM API(답변생성) 청킹(적절히 자르기) 임베딩 + Vector DB(검색진구축) 연결

## 기술 스택
| 항목 | 선택 | 대안 | 선택 이유 |
|------|------|------|----------|
| | | | |

## 핵심 구현
- 주요 로직 설명:
- 코드 실행 방법:

## WHY (의사결정 기록)
1. **Q**: 왜 이 방식을 선택했는가?
   **A**:
2. **Q**: 다르게 구현한다면 어떻게 했을까?
   **A**:

## 트러블슈팅 로그
| # | 문제 상황 | 에러 메시지 | 원인 (Root Cause) | 해결 방법 |
|---|----------|-----------|-------------------|----------|
| 1 | | | | |

## 회고
- 이번 주 배운 점:
- 다음 주 준비할 것:




1. 사전 준비 (문서 저장)
문서를 가져와 작게 쪼갠 뒤, AI가 이해할 수 있는 형태의 암호(숫자 벡터)로 변환하여 데이터베이스에 차곡차곡 저장해 둡니다.

2. 정보 검색 (관련 내용 찾기)
사용자가 질문을 하면, 질문 역시 암호로 변환한 뒤 데이터베이스를 뒤져 질문과 가장 연관성이 높은 문서 조각들을 찾아냅니다.

3. 답변 생성 (최종 답변하기)
미리 찾아낸 문서 조각들을 '참고 자료'로 삼아, AI(GPT, Claude 등)가 사용자의 질문에 대한 정확한 최종 답변을 작성합니다.