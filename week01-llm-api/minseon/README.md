# 1주차: LLM API 연동 - minseon

## 기술 스택
| 항목 | 선택 | 대안 | 선택 이유 |
|------|------|------|----------|
LLM API ㅣ OpenAI GPT-4o ㅣ Anthropic Claude, Google Gemini ㅣ 가장 넓은 개발 생태계 구축되어있음. 오류가 났을 때 찾아볼 수 있는 과거의 예시 많아서 고치기 쉬움. 
응답방식 ㅣ Straming ㅣ Non - Streaming (일괄수신) ㅣ 전체 텍스트가 생성될 때까지 기다려야하는 Non-streaming 말고 생성된 토큰을 바로 클라이언트로 전송해서 보여주면 답답하지 않을거임.
웹 UI ㅣ Streamlit (파이썬 코드만 짜면 알아서 웹사이트 화면을 만들어줌) ㅣ FastAPI + React, Flask + Jinja ㅣ Python만으로 웹 UI 구현해서 시간 아낌
토큰관리 ㅣ Sliding Window (내용 밀어내기)ㅣ Summarization (요약하기) ㅣ	구현 단순. 최근 대화 맥락을 우선적으로 보존하는 것이 답변의 정확도랑 맥락 유지에 유리함. 
환경변수 ㅣ pyton - dotenv ㅣ 시스템 환경변수 직접 설정 ㅣ .env파일로 관리하면 편함. API 인증 키 등 보안 데이터의 안전한 격리 및 관리. .env파일에 비밀번호를 따로 보관해서 인터넷(Git 클로드)에 정보가 유출되는걸 막음
실행 방식 ㅣ 터미널 + 웹 분리 ㅣ 웹, 터미널 ㅣ 챗봇 기능(chat.py) 먼저 테스트하고 웹 화면(app.py) 연결. 에러 발생 시 원인 파악이 빠름 (화면 문제인지, 기능 문제인지 즉시 구분 가능)




## 핵심 구현
- 주요 로직 설명: 사용자입력 -> 대화기록(conversation 리스트)에 추가 -> 용량이 초과하지 않도록 옛날 대화는 지우고 최근 대화만 남김 (Sliding Window) -> AI의 기본 성격(시스템 메시지)과 방금 정리한 '최근 기억'을 OpenAI API(인공지능 두뇌)로 전송 -> Streaming으로 토큰 단위 실시간 출력 -> 토큰 사용량 기록 + 방금 AI가 한 대답도 기억 장치(conversation)에 저장 (다음 대화에서 참고할 수 있게)


- 코드 실행 방법:
1. 패키지 설치
pip install -r requirements.txt

2. .env 파일 생성 (week01-llm-api/minseon/ 안에)
echo "OPENAI_API_KEY=sk-..." > .env

python week01-llm-api/minseon/chat.py (터미널 챗봇 실행)
streamlit run week01-llm-api/minseon/app.py (웹 챗봇 실행) 


## WHY (의사결정 기록)
1. **Q**: 왜 이 방식을 선택했는가?
   **A**:OpenAI가 제일 알고있는게 많고 다양한 레퍼런스를 보유하고 있어서 처음 LLM API를 학습하기 적합하기때문이다. (SDK가 직관적이고 문서화가 잘 되어 있다고해서).  Streaming 방식은 실시간으로 글자를 화면에 출력시키므로 사용자의 답답함을 없앨수았다고 생각했다. Streamlit는 Python만으로 웹 UI 구현 가능하다고했고 별도 프론트엔드 지식 불필요하다고해서 선택했다 
2. **Q**: 다르게 구현한다면 어떻게 했을까?
   **A**:웹 UI를 Stramlit말고 FastAPI + React로 더 세밀한 UI 제어가 가능하게 하고싶다.(UI를 더 보기쉽고 멋지게 구현하고싶음 UX와 함께) 대화저장방식을 DB 저장 (SQLite 등)으로해서 세션 종료 후에도 대화 이력이 유지가 되도록하고싶다. 


## 트러블슈팅 로그
| # | 문제 상황 | 에러 메시지 | 원인 (Root Cause) | 해결 방법 |
|---|----------|-----------|-------------------|----------|
| 1 | st.empty()를 반복 업데이트할 때 발생하는 Streamlit DOM 버그| NotFoundError: 'node'에서 'removeChild' 실행에 실패: 제거할 노드는 이 노드의 자식이 아닙니다.| 전체를 지우고 처음부터 다시 쓰는 과정이 너무 빨리 반복되어서 화면이 버벅거리고 깜빡거림 |  st.write_stream()으로 교체 (기존 글자 뒤에 자연스럽게 이어서 써줌)



## 회고
- 이번 주 배운 점: LLM API 연동하는 법을 자세히 알게되었다. LLM은 기본적으로 기억이 없어서 요청마다 대화 히스토리를 직접 전달해야 멀티턴 대화가 가능한다는 걸 알개되었다.대화가 길어질수록 토큰 비용이 커지니까  Sliding Window로 오래된 메시지를 관리하는것이 좋다는것도 알게되었다. 
- 다음 주 준비할 것: 청킹 뭔지 알아보기




























RAG (Retrieval-Augmented Generation) 검색 증강 세대
LMM이 학습하지 않은 정보에 대해서도 정확한 답변을 제공하기위해 외부문서를 검색해서 컨텍스트로 제공하는 시스템 (참고자료같은거)

RAG 왜 필요해 ?
- 환각현상 (Hallucination)
AI가 모르는 내용을 사실인 것처럼 거짓말하는 문제를 줄일 수 있음
- 최신 정보 부족
LLM은 학습 시점이 정해져 있어(n년까지의 데이터) RAG는 실시간으로 검색해 답변할 수 있음 *거대 언어 모델 대화하는 **LLM의 가장 기본적인 원리 : 다음에 올 단어 맞히기
- 사내 데이터 보안
기업 내부의 비공개 문서는 외부 LLM이 접근못해서 학습하지 못함 (보안상 학습시켜서도 안됨) RAG는 데이터를 모델에 영구적으로 학습시키는 것이 아니고 필요할 때만 참조해서 답변하는거라서 데이터 유출 위험 없이 사내 정보를 활용할 수 있음 *참조(RAG): 질문 해결을 위해 잠시 데이터를 읽고 답변 후 즉시 휘발시켜서 유출위험없음 **기업용 RAG는 보통 외부 통신이 차단된 폐쇄형 환경(On-Premise)이나 데이터 학습 방지 조건이 걸린 보안 API를 사용해서 정보가 외부로 안나감 ~

RAG 주요 구성 요소
1. 임베딩모델 (Embedding Model) : 텍스트(사람이 쓰는 글)을 컴퓨터가 이해할수 있는 숫자(벡터)로 바꿔주는 번역기 
2.벡터 데이터 베이스 (Voter DB) : 숫자로 변환된 데이터들을 저장해둠 (유사도 검색을 위한 저장소)
3. 검색기 (Retriever) : 질문 벡터와 관련된 문서를 찾아냄
4. 생성기 (generator) : 검색된 문서를 바탕으로 답변 생성하는 AI (LLM)

RAG 작동 원리 


O




