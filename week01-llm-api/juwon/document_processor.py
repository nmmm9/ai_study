"""
PDF ë¬¸ì„œ ì²˜ë¦¬ ë° ì„ë² ë”© ìƒì„± ëª¨ë“ˆ
OpenAI Embedding APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë²¡í„°í™”
"""

import os
from typing import List, Tuple
from pypdf import PdfReader
from openai import OpenAI
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import pickle


class DocumentProcessor:
    """PDF ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê³  ì„ë² ë”©ì„ ìƒì„±/ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, client: OpenAI):
        self.client = client
        self.chunks: List[str] = []
        self.embeddings: np.ndarray = None
        self.embedding_model = "text-embedding-3-small"

    def load_pdf(self, pdf_path: str, chunk_size: int = 500) -> None:
        """
        PDF íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì²­í¬ë¡œ ë¶„í• 

        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            chunk_size: ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜
        """
        print(f"ğŸ“„ PDF íŒŒì¼ ë¡œë”© ì¤‘: {pdf_path}")

        reader = PdfReader(pdf_path)
        full_text = ""

        for page_num, page in enumerate(reader.pages, 1):
            text = page.extract_text()
            full_text += text + "\n"
            print(f"  í˜ì´ì§€ {page_num}/{len(reader.pages)} ì²˜ë¦¬ ì™„ë£Œ")

        # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        self.chunks = self._split_text(full_text, chunk_size)
        print(f"âœ… ì´ {len(self.chunks)}ê°œì˜ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ\n")

    def _split_text(self, text: str, chunk_size: int) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í•  (ë¬¸ì¥ ë‹¨ìœ„ ìœ ì§€)"""
        sentences = text.replace('\n', ' ').split('. ')
        chunks = []
        current_chunk = ""

        for sentence in sentences:
            if len(current_chunk) + len(sentence) < chunk_size:
                current_chunk += sentence + ". "
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + ". "

        if current_chunk:
            chunks.append(current_chunk.strip())

        return chunks

    def create_embeddings(self) -> None:
        """ëª¨ë“  ì²­í¬ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±"""
        print("ğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘...")

        embeddings_list = []
        for i, chunk in enumerate(self.chunks, 1):
            response = self.client.embeddings.create(
                model=self.embedding_model,
                input=chunk
            )
            embeddings_list.append(response.data[0].embedding)

            if i % 10 == 0:
                print(f"  {i}/{len(self.chunks)} ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ")

        self.embeddings = np.array(embeddings_list)
        print(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ (shape: {self.embeddings.shape})\n")

    def search_similar_chunks(self, query: str, top_k: int = 3) -> List[Tuple[str, float]]:
        """
        ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜

        Returns:
            [(ì²­í¬ í…ìŠ¤íŠ¸, ìœ ì‚¬ë„ ì ìˆ˜), ...] ë¦¬ìŠ¤íŠ¸
        """
        if self.embeddings is None:
            raise ValueError("ì„ë² ë”©ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. create_embeddings()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        response = self.client.embeddings.create(
            model=self.embedding_model,
            input=query
        )
        query_embedding = np.array([response.data[0].embedding])

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = cosine_similarity(query_embedding, self.embeddings)[0]

        # ìƒìœ„ kê°œ ê²°ê³¼ ì¶”ì¶œ
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        results = [(self.chunks[i], float(similarities[i])) for i in top_indices]

        return results

    def save_embeddings(self, filepath: str) -> None:
        """ì„ë² ë”© ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        data = {
            'chunks': self.chunks,
            'embeddings': self.embeddings
        }
        with open(filepath, 'wb') as f:
            pickle.dump(data, f)
        print(f"ğŸ’¾ ì„ë² ë”© ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}")

    def load_embeddings(self, filepath: str) -> None:
        """ì €ì¥ëœ ì„ë² ë”© ë°ì´í„° ë¡œë“œ"""
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")

        with open(filepath, 'rb') as f:
            data = pickle.load(f)

        self.chunks = data['chunks']
        self.embeddings = data['embeddings']
        print(f"ğŸ“‚ ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.chunks)}ê°œ ì²­í¬")
